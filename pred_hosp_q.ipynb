{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import warnings\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pyodbc\r\n",
    "import pandas_access as pa\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.svm import SVC, LinearSVC\r\n",
    "from sklearn.experimental import enable_hist_gradient_boosting \r\n",
    "from sklearn.ensemble import RandomForestClassifier,HistGradientBoostingClassifier,VotingClassifier,StackingClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.linear_model import Perceptron\r\n",
    "from sklearn.linear_model import SGDClassifier\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score,classification_report\r\n",
    "from sklearn.model_selection import cross_val_predict,GridSearchCV, StratifiedKFold\r\n",
    "from sklearn.ensemble import IsolationForest\r\n",
    "from sklearn.svm import OneClassSVM\r\n",
    "from sklearn.covariance import EllipticEnvelope\r\n",
    "from xgboost import XGBClassifier\r\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler  \r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "from tensorflow import keras\r\n",
    "import tensorflow as tf\r\n",
    "import imblearn\r\n",
    "from imblearn.over_sampling import SMOTE,BorderlineSMOTE,ADASYN,SVMSMOTE\r\n",
    "from imblearn.under_sampling import RandomUnderSampler\r\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\r\n",
    "import seaborn as sns\r\n",
    "from collections import Counter\r\n",
    "import loras\r\n",
    "from sklearn.experimental import enable_iterative_imputer\r\n",
    "from sklearn.impute import IterativeImputer,KNNImputer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "pd.set_option('display.max_columns',200)\r\n",
    "pd.set_option('display.max_rows',200)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "dataset_close=pd.read_csv('data\\hospital_closure\\hospital_closure.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "MDB_2017='data\\hospital_compare\\hc_apr2017\\Hospital.mdb'\r\n",
    "MDB_2016 = 'data\\hospital_compare\\hc_may2016\\Hospital.mdb'\r\n",
    "MDB_2015='data\\hospital_compare\\Copy of HospitalMay2015.mdb'\r\n",
    "MDB_2014='data\\hospital_compare\\HC_May2014.mdb'\r\n",
    "\r\n",
    "DRV = '{Microsoft Access Driver (*.mdb, *.accdb)}'\r\n",
    "PWD = 'pw'\r\n",
    "\r\n",
    "con_2017 = pyodbc.connect('DRIVER={};DBQ={};PWD={}'.format(DRV,MDB_2017,PWD))\r\n",
    "con_2016 = pyodbc.connect('DRIVER={};DBQ={};PWD={}'.format(DRV,MDB_2016,PWD))\r\n",
    "con_2015 = pyodbc.connect('DRIVER={};DBQ={};PWD={}'.format(DRV,MDB_2015,PWD))\r\n",
    "con_2014 = pyodbc.connect('DRIVER={};DBQ={};PWD={}'.format(DRV,MDB_2014,PWD))\r\n",
    "cur_2017 = con_2017.cursor()\r\n",
    "cur_2016 = con_2016.cursor()\r\n",
    "cur_2015 = con_2015.cursor()\r\n",
    "cur_2014 = con_2014.cursor()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "table_name = 'HQI_HOSP_ReadmDeath'\r\n",
    "table_name2='HQI_HOSP_ReadmCompDeath'\r\n",
    "table_name3='HQI_HOSP_Comp'\r\n",
    "query = \"SELECT * FROM {}\".format(table_name)\r\n",
    "query2=\"SELECT * FROM {}\".format(table_name2)\r\n",
    "query3=\"SELECT * FROM {}\".format(table_name3)\r\n",
    "rows_2017 = cur_2017.execute(query).fetchall()\r\n",
    "rows_2017_c=cur_2017.execute(query3).fetchall()\r\n",
    "rows_2016 = cur_2016.execute(query).fetchall()\r\n",
    "rows_2016_c = cur_2016.execute(query3).fetchall()\r\n",
    "rows_2015 = cur_2015.execute(query2).fetchall()\r\n",
    "#rows_2014 = cur_2014.execute(query2).fetchall()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "source": [
    "arr_2017=np.array(rows_2017)\r\n",
    "dataset_2017=pd.DataFrame(arr_2017[:,[0,3,6]],columns=['id','score_name','Score'])\r\n",
    "arr_2017_c=np.array(rows_2017_c)\r\n",
    "dataset_2017_c=pd.DataFrame(arr_2017_c[:,[0,3,6]],columns=['id','score_name','Score'])\r\n",
    "arr_2016=np.array(rows_2016)\r\n",
    "dataset_2016=pd.DataFrame(arr_2016[:,[0,3,6]],columns=['id','score_name','Score'])\r\n",
    "arr_2016_c=np.array(rows_2016_c)\r\n",
    "dataset_2016_c=pd.DataFrame(arr_2016_c[:,[0,3,6]],columns=['id','score_name','Score'])\r\n",
    "arr_2015=np.array(rows_2015)\r\n",
    "dataset_2015=pd.DataFrame(arr_2015[:,[0,3,6]],columns=['id','score_name','Score'])\r\n",
    "#dataset_2014=pd.DataFrame(arr_2014[:,[1,5,6,7,8,9,10]],columns=['id','1','2','3','4','5','6'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "source": [
    "dataset_2015=dataset_2015[dataset_2015['id'].map(lambda x: x.find('F')==-1)]\r\n",
    "dataset_2015.drop(dataset_2015[dataset_2015.id=='670092'].index,inplace=True)\r\n",
    "dataset_2016=dataset_2016[dataset_2016['id'].map(lambda x: x.find('F')==-1)]\r\n",
    "dataset_2016_c=dataset_2016_c[dataset_2016_c['id'].map(lambda x: x.find('F')==-1)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "source": [
    "dataset_2016=pd.concat([dataset_2016,dataset_2016_c],axis=0)\r\n",
    "dataset_2017=pd.concat([dataset_2017,dataset_2017_c],axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "source": [
    "dataset_2015.sort_values(by=['id','score_name'],inplace=True)\r\n",
    "dataset_2016.sort_values(by=['id','score_name'],inplace=True)\r\n",
    "dataset_2017.sort_values(by=['id','score_name'],inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "source": [
    "da_2015=dataset_2015[['id','Score']].to_numpy().reshape(4654,38)\r\n",
    "da_2016=dataset_2016[['id','Score']].to_numpy().reshape(4643,42)\r\n",
    "da_2017=dataset_2017[['id','Score']].to_numpy().reshape(4805,50)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "source": [
    "arr1=[i*2 for i in range(19)]\r\n",
    "arr2=[i*2 for i in range(21)]\r\n",
    "arr3=[i*2 for i in range(25)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "source": [
    "da_2015=np.delete(da_2015,arr1[1:],axis=1)\r\n",
    "da_2016=np.delete(da_2016,arr2[1:],axis=1)\r\n",
    "da_2017=np.delete(da_2017,arr3[1:],axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "source": [
    "da_2015=pd.DataFrame(da_2015,columns=['id','COMP_HIP_KNEE','MORT_30_AMI','MORT_30_COPD','MORT_30_HF','MORT_30_PN','MORT_30_STK','PSI_12_POSTOP_PULMEMB_DVT','PSI_14_POSTOP_DEHIS','PSI_15_ACC_LAC','PSI_4_SURG_COMP','PSI_6_IAT_PTX','PSI_90_SAFETY','READM_30_AMI','READM_30_COPD','READM_30_HF','READM_30_HIP_KNEE','READM_30_HOSP_WIDE','READM_30_PN','READM_30_STK'])\r\n",
    "da_2016=pd.DataFrame(da_2016,columns=['id','COMP_HIP_KNEE','MORT_30_AMI','MORT_30_CABG','MORT_30_COPD','MORT_30_HF','MORT_30_PN','MORT_30_STK','PSI_12_POSTOP_PULMEMB_DVT','PSI_14_POSTOP_DEHIS','PSI_15_ACC_LAC','PSI_4_SURG_COMP','PSI_6_IAT_PTX','PSI_90_SAFETY','READM_30_AMI','READM_30_CABG','READM_30_COPD','READM_30_HF','READM_30_HIP_KNEE','READM_30_HOSP_WIDE','READM_30_PN','READM_30_STK'])\r\n",
    "da_2017=pd.DataFrame(da_2017,columns=['id','COMP_HIP_KNEE','MORT_30_AMI','MORT_30_CABG','MORT_30_COPD','MORT_30_HF','MORT_30_PN','MORT_30_STK','PSI_12_POSTOP_PULMEMB_DVT','PSI_13_POST_SEPSIS','PSI_14_POSTOP_DEHIS','PSI_15_ACC_LAC','PSI_3_ULCER','PSI_4_SURG_COMP','PSI_6_IAT_PTX','PSI_7_CVCBI','PSI_8_POST_HIP','PSI_90_SAFETY','READM_30_AMI','READM_30_CABG','READM_30_COPD','READM_30_HF','READM_30_HIP_KNEE','READM_30_HOSP_WIDE','READM_30_PN','READM_30_STK'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "source": [
    "da_2016.drop(columns=['MORT_30_CABG','READM_30_CABG'],inplace=True)\r\n",
    "da_2017.drop(columns=['MORT_30_CABG','PSI_13_POST_SEPSIS','PSI_3_ULCER','PSI_7_CVCBI','PSI_8_POST_HIP','READM_30_CABG'],inplace=True)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "source": [
    "close_2017=dataset_close[dataset_close['year_close_combined']==2017]\r\n",
    "close_2016=dataset_close[dataset_close['year_close_combined']==2016]\r\n",
    "close_2015=dataset_close[dataset_close['year_close_combined']==2015]\r\n",
    "close_2014=dataset_close[dataset_close['year_close_combined']==2014]\r\n",
    "close_2013=dataset_close[dataset_close['year_close_combined']==2013]\r\n",
    "\r\n",
    "close_2015_=pd.concat([close_2017,close_2016])\r\n",
    "close_2014_=pd.concat([close_2016,close_2015])\r\n",
    "close_2013_=pd.concat([close_2015,close_2014])\r\n",
    "\r\n",
    "#close_2015_=pd.concat([close_2017,close_2016,close_2015])\r\n",
    "#close_2014_=pd.concat([close_2016,close_2015,close_2014])\r\n",
    "#close_2013_=pd.concat([close_2015,close_2014,close_2013])\r\n",
    "da_2017['Closure']=da_2017.id.apply(lambda x:1 if int(x) in np.array(close_2015_['id']) else 0)\r\n",
    "da_2017.drop(da_2017[da_2017['id']==any(close_2013['id'])].index,inplace=True)\r\n",
    "da_2016['Closure']=da_2016.id.apply(lambda x:1 if int(x) in np.array(close_2014_['id']) else 0)\r\n",
    "da_2015['Closure']=da_2015.id.apply(lambda x:1 if int(x) in np.array(close_2013_['id']) else 0)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "close_2016=dataset_close[dataset_close['year_close_combined']==2016]\r\n",
    "close_2015=dataset_close[dataset_close['year_close_combined']==2015]\r\n",
    "close_2014=dataset_close[dataset_close['year_close_combined']==2014]\r\n",
    "close_=pd.concat([close_2016,close_2015,close_2014])\r\n",
    "da_2017['Closure']=da_2017.id.apply(lambda x:1 if int(x) in np.array(close_['id']) else 0)\r\n",
    "da_2016['Closure']=da_2016.id.apply(lambda x:1 if int(x) in np.array(close_['id']) else 0)\r\n",
    "da_2015['Closure']=da_2015.id.apply(lambda x:1 if int(x) in np.array(close_['id']) else 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "source": [
    "da_2017[da_2017['Closure']==1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          id COMP_HIP_KNEE MORT_30_AMI MORT_30_COPD MORT_30_HF MORT_30_PN  \\\n",
       "1012  110205           NaN         NaN          7.3       12.1       20.9   \n",
       "2329  250084           3.5        15.9          8.4       14.2       19.4   \n",
       "4030  450214           NaN         NaN          8.3       11.2       16.5   \n",
       "4101  450605           NaN         NaN          8.2       10.7       15.2   \n",
       "4147  450749           NaN         NaN          8.6       10.9       15.2   \n",
       "\n",
       "     MORT_30_STK PSI_12_POSTOP_PULMEMB_DVT PSI_14_POSTOP_DEHIS PSI_15_ACC_LAC  \\\n",
       "1012         NaN                      5.82                 NaN           1.21   \n",
       "2329        15.0                      4.67                2.24           1.43   \n",
       "4030         NaN                      4.72                2.29           1.24   \n",
       "4101         NaN                       NaN                 NaN           1.69   \n",
       "4147         NaN                       NaN                 NaN           1.41   \n",
       "\n",
       "     PSI_4_SURG_COMP PSI_6_IAT_PTX PSI_90_SAFETY READM_30_AMI READM_30_COPD  \\\n",
       "1012             NaN          0.40          0.89          NaN          21.2   \n",
       "2329             NaN          0.43          0.85         17.8          20.5   \n",
       "4030             NaN          0.40          0.82          NaN          20.2   \n",
       "4101             NaN          0.47          0.96          NaN          18.4   \n",
       "4147             NaN          0.41          0.90          NaN          20.5   \n",
       "\n",
       "     READM_30_HF READM_30_HIP_KNEE READM_30_HOSP_WIDE READM_30_PN  \\\n",
       "1012        23.6               NaN               15.8        18.3   \n",
       "2329        22.0               4.8               15.9        17.0   \n",
       "4030        20.1               NaN               15.8        15.9   \n",
       "4101        21.3               NaN               14.7        15.1   \n",
       "4147        22.4               NaN               15.9        17.9   \n",
       "\n",
       "     READM_30_STK  Closure  \n",
       "1012          NaN        1  \n",
       "2329         13.5        1  \n",
       "4030          NaN        1  \n",
       "4101          NaN        1  \n",
       "4147          NaN        1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>COMP_HIP_KNEE</th>\n",
       "      <th>MORT_30_AMI</th>\n",
       "      <th>MORT_30_COPD</th>\n",
       "      <th>MORT_30_HF</th>\n",
       "      <th>MORT_30_PN</th>\n",
       "      <th>MORT_30_STK</th>\n",
       "      <th>PSI_12_POSTOP_PULMEMB_DVT</th>\n",
       "      <th>PSI_14_POSTOP_DEHIS</th>\n",
       "      <th>PSI_15_ACC_LAC</th>\n",
       "      <th>PSI_4_SURG_COMP</th>\n",
       "      <th>PSI_6_IAT_PTX</th>\n",
       "      <th>PSI_90_SAFETY</th>\n",
       "      <th>READM_30_AMI</th>\n",
       "      <th>READM_30_COPD</th>\n",
       "      <th>READM_30_HF</th>\n",
       "      <th>READM_30_HIP_KNEE</th>\n",
       "      <th>READM_30_HOSP_WIDE</th>\n",
       "      <th>READM_30_PN</th>\n",
       "      <th>READM_30_STK</th>\n",
       "      <th>Closure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>110205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.3</td>\n",
       "      <td>12.1</td>\n",
       "      <td>20.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.2</td>\n",
       "      <td>23.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.8</td>\n",
       "      <td>18.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>250084</td>\n",
       "      <td>3.5</td>\n",
       "      <td>15.9</td>\n",
       "      <td>8.4</td>\n",
       "      <td>14.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.85</td>\n",
       "      <td>17.8</td>\n",
       "      <td>20.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4030</th>\n",
       "      <td>450214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>16.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.72</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101</th>\n",
       "      <td>450605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>15.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.4</td>\n",
       "      <td>21.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.7</td>\n",
       "      <td>15.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>450749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.6</td>\n",
       "      <td>10.9</td>\n",
       "      <td>15.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.5</td>\n",
       "      <td>22.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.9</td>\n",
       "      <td>17.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 355
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "source": [
    "da_2016[da_2016['Closure']==1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          id COMP_HIP_KNEE MORT_30_AMI MORT_30_COPD MORT_30_HF MORT_30_PN  \\\n",
       "356   050196           NaN         NaN          NaN        NaN        NaN   \n",
       "439   050435           2.9         NaN          7.9       10.6       12.3   \n",
       "1092  140026           2.9        13.6          7.8       10.7       12.2   \n",
       "1492  170010           NaN         NaN          7.8       13.1       12.3   \n",
       "1675  180117           NaN         NaN          7.3       12.0       13.4   \n",
       "2265  250084           3.6        15.1          8.5       13.7       16.1   \n",
       "2368  260116           4.4         NaN          5.8       10.6       13.7   \n",
       "2582  290020           NaN         NaN          NaN        NaN        NaN   \n",
       "3250  370051           NaN         NaN          6.8       10.2       10.8   \n",
       "3278  370169           NaN         NaN          NaN        NaN       11.9   \n",
       "3638  420016           NaN         NaN          8.0       12.5       14.8   \n",
       "3656  420054           NaN         NaN          8.3       11.5       11.9   \n",
       "3771  440051           NaN         NaN          7.9       15.3       12.8   \n",
       "3850  450005           NaN         NaN          8.0       13.0       10.9   \n",
       "3929  450214           NaN         NaN          NaN       12.1       12.1   \n",
       "3983  450497           NaN         NaN          7.7       13.8       11.1   \n",
       "4002  450605           NaN         NaN          7.8        9.9        9.7   \n",
       "\n",
       "     MORT_30_STK PSI_12_POSTOP_PULMEMB_DVT PSI_14_POSTOP_DEHIS PSI_15_ACC_LAC  \\\n",
       "356          NaN                       NaN                 NaN            NaN   \n",
       "439          NaN                      3.91                1.64           1.70   \n",
       "1092        15.2                      4.40                1.60           1.06   \n",
       "1492        15.4                      4.85                 NaN           1.85   \n",
       "1675         NaN                      3.80                 NaN           1.58   \n",
       "2265        16.0                      3.80                1.64           1.65   \n",
       "2368        15.1                      4.73                1.64           1.79   \n",
       "2582         NaN                       NaN                 NaN           1.80   \n",
       "3250         NaN                       NaN                 NaN           1.75   \n",
       "3278         NaN                       NaN                 NaN           1.79   \n",
       "3638         NaN                       NaN                 NaN           1.69   \n",
       "3656         NaN                       NaN                 NaN           1.65   \n",
       "3771         NaN                       NaN                 NaN           1.65   \n",
       "3850         NaN                      3.71                1.66           1.23   \n",
       "3929         NaN                      3.69                1.67           1.81   \n",
       "3983         NaN                       NaN                 NaN           1.57   \n",
       "4002         NaN                      4.20                 NaN           2.08   \n",
       "\n",
       "     PSI_4_SURG_COMP PSI_6_IAT_PTX PSI_90_SAFETY READM_30_AMI READM_30_COPD  \\\n",
       "356              NaN           NaN          0.81          NaN           NaN   \n",
       "439              NaN          0.37          0.74          NaN          19.7   \n",
       "1092             NaN          0.36          0.64         17.2          20.2   \n",
       "1492             NaN          0.38          0.84          NaN          19.2   \n",
       "1675             NaN          0.38          0.72          NaN          19.7   \n",
       "2265             NaN          0.39          0.76         18.1          20.5   \n",
       "2368             NaN          0.37          0.81          NaN          21.4   \n",
       "2582             NaN          0.39          0.81          NaN           NaN   \n",
       "3250             NaN          0.38          0.80          NaN          20.0   \n",
       "3278             NaN          0.39          0.81          NaN          19.6   \n",
       "3638             NaN          0.38          0.78          NaN          20.8   \n",
       "3656             NaN          0.38          0.85          NaN          20.1   \n",
       "3771             NaN          0.38          0.76          NaN          20.8   \n",
       "3850             NaN          0.46          0.65          NaN          18.7   \n",
       "3929             NaN          0.38          0.76          NaN          20.6   \n",
       "3983             NaN          0.38          0.75          NaN          19.0   \n",
       "4002             NaN          0.43          0.86          NaN          18.4   \n",
       "\n",
       "     READM_30_HF READM_30_HIP_KNEE READM_30_HOSP_WIDE READM_30_PN  \\\n",
       "356          NaN               NaN                NaN         NaN   \n",
       "439         22.0               4.4               14.4        17.2   \n",
       "1092        20.8               4.7               15.5        17.6   \n",
       "1492        20.5               NaN               15.8        15.1   \n",
       "1675        24.2               NaN               15.2        17.8   \n",
       "2265        22.2               4.7               14.9        16.9   \n",
       "2368        22.7               5.4               15.6        18.0   \n",
       "2582         NaN               NaN                NaN         NaN   \n",
       "3250        20.9               NaN               15.3        17.0   \n",
       "3278         NaN               NaN               15.7        18.1   \n",
       "3638        23.5               NaN               16.6        17.8   \n",
       "3656        21.4               NaN               15.5        17.5   \n",
       "3771        22.1               NaN               15.0        16.8   \n",
       "3850        20.8               NaN               15.0        16.0   \n",
       "3929        22.1               NaN               14.8        15.9   \n",
       "3983        22.1               NaN               15.1        17.9   \n",
       "4002        20.0               NaN               14.1        16.1   \n",
       "\n",
       "     READM_30_STK  Closure  \n",
       "356           NaN        1  \n",
       "439           NaN        1  \n",
       "1092         12.1        1  \n",
       "1492         11.9        1  \n",
       "1675          NaN        1  \n",
       "2265         13.5        1  \n",
       "2368          NaN        1  \n",
       "2582          NaN        1  \n",
       "3250          NaN        1  \n",
       "3278          NaN        1  \n",
       "3638          NaN        1  \n",
       "3656          NaN        1  \n",
       "3771          NaN        1  \n",
       "3850          NaN        1  \n",
       "3929          NaN        1  \n",
       "3983          NaN        1  \n",
       "4002          NaN        1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>COMP_HIP_KNEE</th>\n",
       "      <th>MORT_30_AMI</th>\n",
       "      <th>MORT_30_COPD</th>\n",
       "      <th>MORT_30_HF</th>\n",
       "      <th>MORT_30_PN</th>\n",
       "      <th>MORT_30_STK</th>\n",
       "      <th>PSI_12_POSTOP_PULMEMB_DVT</th>\n",
       "      <th>PSI_14_POSTOP_DEHIS</th>\n",
       "      <th>PSI_15_ACC_LAC</th>\n",
       "      <th>PSI_4_SURG_COMP</th>\n",
       "      <th>PSI_6_IAT_PTX</th>\n",
       "      <th>PSI_90_SAFETY</th>\n",
       "      <th>READM_30_AMI</th>\n",
       "      <th>READM_30_COPD</th>\n",
       "      <th>READM_30_HF</th>\n",
       "      <th>READM_30_HIP_KNEE</th>\n",
       "      <th>READM_30_HOSP_WIDE</th>\n",
       "      <th>READM_30_PN</th>\n",
       "      <th>READM_30_STK</th>\n",
       "      <th>Closure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>050196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>050435</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>12.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.91</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.7</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>17.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>140026</td>\n",
       "      <td>2.9</td>\n",
       "      <td>13.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>10.7</td>\n",
       "      <td>12.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>4.40</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>17.2</td>\n",
       "      <td>20.2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.6</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>170010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8</td>\n",
       "      <td>13.1</td>\n",
       "      <td>12.3</td>\n",
       "      <td>15.4</td>\n",
       "      <td>4.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.1</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>180117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.7</td>\n",
       "      <td>24.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>250084</td>\n",
       "      <td>3.6</td>\n",
       "      <td>15.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>13.7</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.76</td>\n",
       "      <td>18.1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>22.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>14.9</td>\n",
       "      <td>16.9</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>260116</td>\n",
       "      <td>4.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>13.7</td>\n",
       "      <td>15.1</td>\n",
       "      <td>4.73</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.4</td>\n",
       "      <td>22.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>15.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>290020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>370051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.8</td>\n",
       "      <td>10.2</td>\n",
       "      <td>10.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>370169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.7</td>\n",
       "      <td>18.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638</th>\n",
       "      <td>420016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>14.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.6</td>\n",
       "      <td>17.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3656</th>\n",
       "      <td>420054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.3</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.1</td>\n",
       "      <td>21.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>440051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.9</td>\n",
       "      <td>15.3</td>\n",
       "      <td>12.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.8</td>\n",
       "      <td>22.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>450005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.71</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.7</td>\n",
       "      <td>20.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>450214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.1</td>\n",
       "      <td>12.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.6</td>\n",
       "      <td>22.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>450497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>450605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.1</td>\n",
       "      <td>16.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 356
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "source": [
    "da_2015[da_2015['Closure']==1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          id COMP_HIP_KNEE MORT_30_AMI MORT_30_COPD MORT_30_HF MORT_30_PN  \\\n",
       "205   040042           NaN        14.2          9.4       11.3       14.1   \n",
       "443   050435           2.8         NaN          8.0       10.4       11.6   \n",
       "834   100239           3.7        15.0          7.1       12.5       11.0   \n",
       "977   110183           NaN         NaN          7.0       12.9       12.2   \n",
       "1095  140026           3.3        14.2          6.7        9.8       12.3   \n",
       "1497  170010           3.2         NaN          7.9       13.4       15.1   \n",
       "1679  180117           NaN         NaN          7.5       11.3       14.9   \n",
       "1689  180149           NaN         NaN          6.3       11.5       11.2   \n",
       "1725  190009           NaN         NaN          NaN        NaN        NaN   \n",
       "1843  200025           3.4        14.4          7.3       11.5       10.0   \n",
       "1941  220067           3.9        14.9          6.2       11.0        9.6   \n",
       "2261  250051           NaN         NaN          NaN        NaN       12.4   \n",
       "2274  250084           3.7        15.5          9.8       14.1       15.1   \n",
       "2375  260116           3.3         NaN          5.9       12.3       12.7   \n",
       "2587  290020           NaN         NaN          NaN        NaN        NaN   \n",
       "3257  370051           NaN         NaN          6.5       11.0       11.3   \n",
       "3662  420054           NaN         NaN          8.4       11.9       12.1   \n",
       "3823  440174           NaN         NaN          7.1       11.1       11.1   \n",
       "3857  450005           NaN        14.0          9.0       15.7       12.2   \n",
       "3927  450188           NaN         NaN          7.6       11.6        9.7   \n",
       "3971  450373           NaN         NaN          7.4       11.2       10.2   \n",
       "3994  450497           NaN         NaN          7.9       14.5       12.0   \n",
       "4108  450884           NaN         NaN          7.3       11.2       11.2   \n",
       "4603  670002           NaN         NaN          6.9       11.4       13.0   \n",
       "\n",
       "     MORT_30_STK PSI_12_POSTOP_PULMEMB_DVT PSI_14_POSTOP_DEHIS PSI_15_ACC_LAC  \\\n",
       "205         16.2                      4.67                1.80           1.81   \n",
       "443          NaN                      4.11                1.87           2.10   \n",
       "834         14.1                      4.43                1.86           1.53   \n",
       "977          NaN                      3.82                1.87           1.47   \n",
       "1095        16.8                      3.77                1.80           1.11   \n",
       "1497        15.6                      4.91                1.88           1.94   \n",
       "1679         NaN                      4.26                 NaN           1.72   \n",
       "1689         NaN                       NaN                 NaN           1.76   \n",
       "1725         NaN                      4.54                 NaN           2.19   \n",
       "1843         NaN                      3.89                1.86           1.82   \n",
       "1941        16.1                      2.57                2.11           1.60   \n",
       "2261         NaN                       NaN                 NaN           1.94   \n",
       "2274        15.1                      3.14                1.84           1.36   \n",
       "2375        16.9                      4.11                1.83           1.47   \n",
       "2587         NaN                       NaN                 NaN           1.95   \n",
       "3257         NaN                       NaN                 NaN           1.87   \n",
       "3662         NaN                       NaN                 NaN           1.77   \n",
       "3823         NaN                       NaN                 NaN           1.88   \n",
       "3857         NaN                      3.88                1.86           1.22   \n",
       "3927         NaN                       NaN                 NaN           1.76   \n",
       "3971         NaN                       NaN                 NaN           1.89   \n",
       "3994        15.3                      4.48                 NaN           1.68   \n",
       "4108         NaN                       NaN                 NaN           1.83   \n",
       "4603         NaN                      3.99                 NaN           1.45   \n",
       "\n",
       "     PSI_4_SURG_COMP PSI_6_IAT_PTX PSI_90_SAFETY READM_30_AMI READM_30_COPD  \\\n",
       "205              NaN          0.37          0.80          NaN          22.1   \n",
       "443              NaN          0.39          0.84          NaN          20.4   \n",
       "834           103.97          0.42          0.73          NaN          19.6   \n",
       "977              NaN          0.39          0.70          NaN          21.0   \n",
       "1095             NaN          0.38          0.62         18.7          22.3   \n",
       "1497             NaN          0.40          0.88          NaN          19.5   \n",
       "1679             NaN          0.40          0.79          NaN          21.2   \n",
       "1689             NaN          0.41          0.83          NaN          22.8   \n",
       "1725             NaN          0.41          0.92          NaN           NaN   \n",
       "1843             NaN          0.40          0.79          NaN          20.5   \n",
       "1941          107.28          0.66          0.82         18.1          21.0   \n",
       "2261             NaN          0.41          0.88          NaN          21.0   \n",
       "2274             NaN          0.35          0.71         18.5          20.7   \n",
       "2375             NaN          0.38          0.71          NaN          21.3   \n",
       "2587             NaN          0.41          0.88          NaN           NaN   \n",
       "3257             NaN          0.40          0.86          NaN          19.8   \n",
       "3662             NaN          0.40          0.91          NaN          20.5   \n",
       "3823             NaN          0.41          0.86          NaN          21.3   \n",
       "3857             NaN          0.38          0.66         17.5          19.2   \n",
       "3927             NaN          0.40          0.83          NaN          20.1   \n",
       "3971             NaN          0.46          0.87          NaN          19.4   \n",
       "3994             NaN          0.40          0.81          NaN          19.9   \n",
       "4108             NaN          0.40          0.84          NaN          19.6   \n",
       "4603             NaN          0.39          0.72          NaN          20.0   \n",
       "\n",
       "     READM_30_HF READM_30_HIP_KNEE READM_30_HOSP_WIDE READM_30_PN  \\\n",
       "205         23.1               NaN               17.2        19.3   \n",
       "443         22.6               4.3               15.7        17.7   \n",
       "834         22.3               5.6               15.4        16.9   \n",
       "977         23.2               NaN               15.0        17.3   \n",
       "1095        21.0               5.1               15.7        18.9   \n",
       "1497        22.1               5.3               14.9        16.8   \n",
       "1679        24.1               NaN               16.9        18.5   \n",
       "1689        27.4               NaN               16.7        19.2   \n",
       "1725         NaN               NaN               16.1        17.9   \n",
       "1843        22.6               5.1               15.7        16.5   \n",
       "1941        24.4               6.2               15.0        19.7   \n",
       "2261         NaN               NaN                NaN        17.6   \n",
       "2274        22.9               5.2               15.7        17.2   \n",
       "2375        24.2               6.3               16.3        17.0   \n",
       "2587         NaN               NaN                NaN         NaN   \n",
       "3257        21.6               NaN               15.4        18.1   \n",
       "3662        22.2               NaN               16.0        17.0   \n",
       "3823        23.6               NaN               15.0        18.6   \n",
       "3857        22.4               NaN               15.8        15.7   \n",
       "3927        23.1               NaN               15.6        17.2   \n",
       "3971        23.8               NaN               15.6        17.7   \n",
       "3994        24.3               NaN               16.1        17.8   \n",
       "4108        22.6               NaN               14.0        16.7   \n",
       "4603        22.2               NaN               15.9        17.0   \n",
       "\n",
       "     READM_30_STK  Closure  \n",
       "205          12.6        1  \n",
       "443           NaN        1  \n",
       "834          14.0        1  \n",
       "977           NaN        1  \n",
       "1095         13.0        1  \n",
       "1497         13.0        1  \n",
       "1679          NaN        1  \n",
       "1689          NaN        1  \n",
       "1725          NaN        1  \n",
       "1843          NaN        1  \n",
       "1941         14.1        1  \n",
       "2261          NaN        1  \n",
       "2274         14.2        1  \n",
       "2375         12.3        1  \n",
       "2587          NaN        1  \n",
       "3257          NaN        1  \n",
       "3662          NaN        1  \n",
       "3823          NaN        1  \n",
       "3857          NaN        1  \n",
       "3927          NaN        1  \n",
       "3971          NaN        1  \n",
       "3994         13.9        1  \n",
       "4108          NaN        1  \n",
       "4603          NaN        1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>COMP_HIP_KNEE</th>\n",
       "      <th>MORT_30_AMI</th>\n",
       "      <th>MORT_30_COPD</th>\n",
       "      <th>MORT_30_HF</th>\n",
       "      <th>MORT_30_PN</th>\n",
       "      <th>MORT_30_STK</th>\n",
       "      <th>PSI_12_POSTOP_PULMEMB_DVT</th>\n",
       "      <th>PSI_14_POSTOP_DEHIS</th>\n",
       "      <th>PSI_15_ACC_LAC</th>\n",
       "      <th>PSI_4_SURG_COMP</th>\n",
       "      <th>PSI_6_IAT_PTX</th>\n",
       "      <th>PSI_90_SAFETY</th>\n",
       "      <th>READM_30_AMI</th>\n",
       "      <th>READM_30_COPD</th>\n",
       "      <th>READM_30_HF</th>\n",
       "      <th>READM_30_HIP_KNEE</th>\n",
       "      <th>READM_30_HOSP_WIDE</th>\n",
       "      <th>READM_30_PN</th>\n",
       "      <th>READM_30_STK</th>\n",
       "      <th>Closure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>040042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.3</td>\n",
       "      <td>14.1</td>\n",
       "      <td>16.2</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.1</td>\n",
       "      <td>23.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>050435</td>\n",
       "      <td>2.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>11.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.11</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.4</td>\n",
       "      <td>22.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>15.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>100239</td>\n",
       "      <td>3.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>4.43</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.53</td>\n",
       "      <td>103.97</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.6</td>\n",
       "      <td>22.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>15.4</td>\n",
       "      <td>16.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>110183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.82</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>140026</td>\n",
       "      <td>3.3</td>\n",
       "      <td>14.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.8</td>\n",
       "      <td>12.3</td>\n",
       "      <td>16.8</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.62</td>\n",
       "      <td>18.7</td>\n",
       "      <td>22.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>15.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>170010</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.9</td>\n",
       "      <td>13.4</td>\n",
       "      <td>15.1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>4.91</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.5</td>\n",
       "      <td>22.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>14.9</td>\n",
       "      <td>16.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>180117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.5</td>\n",
       "      <td>11.3</td>\n",
       "      <td>14.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.2</td>\n",
       "      <td>24.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>18.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>180149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.3</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.8</td>\n",
       "      <td>27.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.7</td>\n",
       "      <td>19.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>190009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>200025</td>\n",
       "      <td>3.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>11.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.89</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>15.7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>220067</td>\n",
       "      <td>3.9</td>\n",
       "      <td>14.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.60</td>\n",
       "      <td>107.28</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.82</td>\n",
       "      <td>18.1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>14.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>250051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>250084</td>\n",
       "      <td>3.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>9.8</td>\n",
       "      <td>14.1</td>\n",
       "      <td>15.1</td>\n",
       "      <td>15.1</td>\n",
       "      <td>3.14</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.71</td>\n",
       "      <td>18.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>22.9</td>\n",
       "      <td>5.2</td>\n",
       "      <td>15.7</td>\n",
       "      <td>17.2</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>260116</td>\n",
       "      <td>3.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.9</td>\n",
       "      <td>12.3</td>\n",
       "      <td>12.7</td>\n",
       "      <td>16.9</td>\n",
       "      <td>4.11</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.3</td>\n",
       "      <td>24.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>16.3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>290020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>370051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.4</td>\n",
       "      <td>18.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3662</th>\n",
       "      <td>420054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.4</td>\n",
       "      <td>11.9</td>\n",
       "      <td>12.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.5</td>\n",
       "      <td>22.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823</th>\n",
       "      <td>440174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.3</td>\n",
       "      <td>23.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>450005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>12.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.88</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.66</td>\n",
       "      <td>17.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>22.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3927</th>\n",
       "      <td>450188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>9.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.1</td>\n",
       "      <td>23.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.6</td>\n",
       "      <td>17.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>450373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.4</td>\n",
       "      <td>23.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.6</td>\n",
       "      <td>17.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>450497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.9</td>\n",
       "      <td>14.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.9</td>\n",
       "      <td>24.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>450884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>670002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.9</td>\n",
       "      <td>11.4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 357
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "source": [
    "da_2017=da_2017.replace({'Not Available':np.nan,' Not Available':np.nan})\r\n",
    "da_2016=da_2016.replace({'Not Available':np.nan,' Not Available':np.nan})\r\n",
    "da_2015=da_2015.replace({'Not Available':np.nan,' Not Available':np.nan})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "source": [
    "da_=pd.concat([da_2017,da_2016,da_2015])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "source": [
    "da_['id']=pd.to_numeric(da_['id']).astype(int)\r\n",
    "da_.loc[da_['id']==40021,'Closure']=0\r\n",
    "da_.loc[da_['id']==200025,'Closure']=0\r\n",
    "da_.loc[da_['id']==260147,'Closure']=0\r\n",
    "da_.loc[da_['id']==440047,'Closure']=0\r\n",
    "da_.loc[da_['id']==180149,'Closure']=0\r\n",
    "da_.loc[da_['id']==450832,'Closure']=0\r\n",
    "da_.loc[da_['id']==670052,'Closure']=0\r\n",
    "da_.drop(columns=['id'],inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "source": [
    "for col in da_:\r\n",
    "    da_[col]=pd.to_numeric(da_[col])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "source": [
    "da_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      COMP_HIP_KNEE  MORT_30_AMI  MORT_30_COPD  MORT_30_HF  MORT_30_PN  \\\n",
       "0               3.8         12.5           9.3        12.4        15.5   \n",
       "1               3.0         16.0           7.6        15.5        20.8   \n",
       "2               3.8         16.7           7.1        15.6        18.2   \n",
       "3               NaN          NaN           9.3        14.4        18.8   \n",
       "4               NaN          NaN           8.2        12.7        15.7   \n",
       "...             ...          ...           ...         ...         ...   \n",
       "4649            NaN          NaN           NaN         NaN         NaN   \n",
       "4650            NaN          NaN           NaN         NaN         NaN   \n",
       "4651            NaN          NaN           NaN         NaN         NaN   \n",
       "4652            NaN          NaN           NaN         NaN         NaN   \n",
       "4653            NaN          NaN           NaN         NaN         NaN   \n",
       "\n",
       "      MORT_30_STK  PSI_12_POSTOP_PULMEMB_DVT  PSI_14_POSTOP_DEHIS  \\\n",
       "0            15.4                       3.32                 2.72   \n",
       "1            15.5                       5.63                 2.11   \n",
       "2            17.9                       3.85                 2.50   \n",
       "3            16.6                       4.57                  NaN   \n",
       "4             NaN                        NaN                  NaN   \n",
       "...           ...                        ...                  ...   \n",
       "4649          NaN                       4.44                  NaN   \n",
       "4650          NaN                        NaN                  NaN   \n",
       "4651          NaN                        NaN                  NaN   \n",
       "4652          NaN                        NaN                  NaN   \n",
       "4653          NaN                        NaN                  NaN   \n",
       "\n",
       "      PSI_15_ACC_LAC  PSI_4_SURG_COMP  PSI_6_IAT_PTX  PSI_90_SAFETY  \\\n",
       "0               1.35           168.26           0.36           0.68   \n",
       "1               1.25           179.05           0.47           0.85   \n",
       "2               1.93           198.33           0.41           0.91   \n",
       "3               1.20              NaN           0.40           0.79   \n",
       "4               1.41              NaN           0.41           0.90   \n",
       "...              ...              ...            ...            ...   \n",
       "4649            1.76              NaN           0.40           0.92   \n",
       "4650             NaN              NaN            NaN            NaN   \n",
       "4651             NaN              NaN            NaN            NaN   \n",
       "4652             NaN              NaN            NaN            NaN   \n",
       "4653             NaN              NaN            NaN            NaN   \n",
       "\n",
       "      READM_30_AMI  READM_30_COPD  READM_30_HF  READM_30_HIP_KNEE  \\\n",
       "0             16.5           21.1         21.4                5.1   \n",
       "1             16.7           18.0         21.9                5.7   \n",
       "2             16.1           19.8         20.6                5.0   \n",
       "3              NaN           19.9         21.1                NaN   \n",
       "4              NaN           19.2         23.1                NaN   \n",
       "...            ...            ...          ...                ...   \n",
       "4649           NaN            NaN          NaN                NaN   \n",
       "4650           NaN            NaN          NaN                NaN   \n",
       "4651           NaN            NaN          NaN                NaN   \n",
       "4652           NaN            NaN          NaN                NaN   \n",
       "4653           NaN            NaN          NaN                NaN   \n",
       "\n",
       "      READM_30_HOSP_WIDE  READM_30_PN  READM_30_STK  Closure  \n",
       "0                   15.4         18.7          12.7        0  \n",
       "1                   14.9         16.4          13.4        0  \n",
       "2                   15.4         17.9          12.0        0  \n",
       "3                   16.6         17.3          12.7        0  \n",
       "4                   15.7         16.0           NaN        0  \n",
       "...                  ...          ...           ...      ...  \n",
       "4649                14.9          NaN           NaN        0  \n",
       "4650                 NaN          NaN           NaN        0  \n",
       "4651                 NaN          NaN           NaN        0  \n",
       "4652                 NaN          NaN           NaN        0  \n",
       "4653                 NaN          NaN           NaN        0  \n",
       "\n",
       "[14102 rows x 20 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMP_HIP_KNEE</th>\n",
       "      <th>MORT_30_AMI</th>\n",
       "      <th>MORT_30_COPD</th>\n",
       "      <th>MORT_30_HF</th>\n",
       "      <th>MORT_30_PN</th>\n",
       "      <th>MORT_30_STK</th>\n",
       "      <th>PSI_12_POSTOP_PULMEMB_DVT</th>\n",
       "      <th>PSI_14_POSTOP_DEHIS</th>\n",
       "      <th>PSI_15_ACC_LAC</th>\n",
       "      <th>PSI_4_SURG_COMP</th>\n",
       "      <th>PSI_6_IAT_PTX</th>\n",
       "      <th>PSI_90_SAFETY</th>\n",
       "      <th>READM_30_AMI</th>\n",
       "      <th>READM_30_COPD</th>\n",
       "      <th>READM_30_HF</th>\n",
       "      <th>READM_30_HIP_KNEE</th>\n",
       "      <th>READM_30_HOSP_WIDE</th>\n",
       "      <th>READM_30_PN</th>\n",
       "      <th>READM_30_STK</th>\n",
       "      <th>Closure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.8</td>\n",
       "      <td>12.5</td>\n",
       "      <td>9.3</td>\n",
       "      <td>12.4</td>\n",
       "      <td>15.5</td>\n",
       "      <td>15.4</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1.35</td>\n",
       "      <td>168.26</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.68</td>\n",
       "      <td>16.5</td>\n",
       "      <td>21.1</td>\n",
       "      <td>21.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>18.7</td>\n",
       "      <td>12.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>15.5</td>\n",
       "      <td>20.8</td>\n",
       "      <td>15.5</td>\n",
       "      <td>5.63</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.25</td>\n",
       "      <td>179.05</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.85</td>\n",
       "      <td>16.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>14.9</td>\n",
       "      <td>16.4</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.8</td>\n",
       "      <td>16.7</td>\n",
       "      <td>7.1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>17.9</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.93</td>\n",
       "      <td>198.33</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.91</td>\n",
       "      <td>16.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>17.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.3</td>\n",
       "      <td>14.4</td>\n",
       "      <td>18.8</td>\n",
       "      <td>16.6</td>\n",
       "      <td>4.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.9</td>\n",
       "      <td>21.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.6</td>\n",
       "      <td>17.3</td>\n",
       "      <td>12.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>15.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.2</td>\n",
       "      <td>23.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4653</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14102 rows × 20 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 202
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "list(da_.columns[:-1])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['COMP_HIP_KNEE',\n",
       " 'MORT_30_AMI',\n",
       " 'MORT_30_COPD',\n",
       " 'MORT_30_HF',\n",
       " 'MORT_30_PN',\n",
       " 'MORT_30_STK',\n",
       " 'PSI_12_POSTOP_PULMEMB_DVT',\n",
       " 'PSI_14_POSTOP_DEHIS',\n",
       " 'PSI_15_ACC_LAC',\n",
       " 'PSI_4_SURG_COMP',\n",
       " 'PSI_6_IAT_PTX',\n",
       " 'PSI_90_SAFETY',\n",
       " 'READM_30_AMI',\n",
       " 'READM_30_COPD',\n",
       " 'READM_30_HF',\n",
       " 'READM_30_HIP_KNEE',\n",
       " 'READM_30_HOSP_WIDE',\n",
       " 'READM_30_PN',\n",
       " 'READM_30_STK']"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "source": [
    "da_.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       COMP_HIP_KNEE  MORT_30_AMI  MORT_30_COPD    MORT_30_HF    MORT_30_PN  \\\n",
       "count    8233.000000  7282.000000  10900.000000  10995.000000  12275.000000   \n",
       "mean        3.185461    14.363142      7.913459     11.959345     13.345222   \n",
       "std         0.609817     1.343128      1.067743      1.469456      2.866427   \n",
       "min         1.400000     9.400000      4.600000      6.000000      6.400000   \n",
       "25%         2.800000    13.500000      7.200000     11.000000     11.100000   \n",
       "50%         3.100000    14.300000      7.800000     11.900000     12.800000   \n",
       "75%         3.500000    15.200000      8.500000     12.900000     15.400000   \n",
       "max         6.900000    20.600000     14.100000     18.500000     26.800000   \n",
       "\n",
       "       MORT_30_STK  PSI_12_POSTOP_PULMEMB_DVT  PSI_14_POSTOP_DEHIS  \\\n",
       "count  8284.000000                9036.000000          7751.000000   \n",
       "mean     15.044532                   4.518752             1.978051   \n",
       "std       1.712835                   1.722131             0.435237   \n",
       "min       8.600000                   0.860000             0.860000   \n",
       "25%      13.900000                   3.430000             1.650000   \n",
       "50%      14.900000                   4.200000             1.880000   \n",
       "75%      16.100000                   5.200000             2.230000   \n",
       "max      23.800000                  20.880000             4.980000   \n",
       "\n",
       "       PSI_15_ACC_LAC  PSI_4_SURG_COMP  PSI_6_IAT_PTX  PSI_90_SAFETY  \\\n",
       "count     9631.000000      5502.000000    9650.000000    9706.000000   \n",
       "mean         1.726129       124.304022       0.400696       0.848702   \n",
       "std          0.644749        20.741338       0.072136       0.183101   \n",
       "min          0.260000        56.260000       0.180000       0.370000   \n",
       "25%          1.300000       109.320000       0.360000       0.730000   \n",
       "50%          1.630000       123.605000       0.390000       0.830000   \n",
       "75%          2.020000       137.985000       0.430000       0.930000   \n",
       "max          7.220000       212.160000       0.880000       2.140000   \n",
       "\n",
       "       READM_30_AMI  READM_30_COPD   READM_30_HF  READM_30_HIP_KNEE  \\\n",
       "count   6632.000000   11103.000000  11212.000000        8266.000000   \n",
       "mean      17.252141      20.345375     22.234267           4.895717   \n",
       "std        1.119150       1.313005      1.610627           0.664587   \n",
       "min       13.100000      15.500000     15.800000           2.400000   \n",
       "25%       16.500000      19.500000     21.200000           4.500000   \n",
       "50%       17.200000      20.300000     22.100000           4.800000   \n",
       "75%       18.000000      21.100000     23.200000           5.300000   \n",
       "max       21.700000      28.000000     31.700000           9.400000   \n",
       "\n",
       "       READM_30_HOSP_WIDE   READM_30_PN  READM_30_STK       Closure  \n",
       "count        13305.000000  12309.000000   8109.000000  14102.000000  \n",
       "mean            15.470943     17.133959     12.886496      0.003120  \n",
       "std              0.889226      1.292103      1.174144      0.055773  \n",
       "min             10.800000     12.900000      8.700000      0.000000  \n",
       "25%             14.900000     16.300000     12.100000      0.000000  \n",
       "50%             15.400000     17.000000     12.800000      0.000000  \n",
       "75%             15.900000     17.900000     13.500000      0.000000  \n",
       "max             21.400000     24.700000     18.500000      1.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMP_HIP_KNEE</th>\n",
       "      <th>MORT_30_AMI</th>\n",
       "      <th>MORT_30_COPD</th>\n",
       "      <th>MORT_30_HF</th>\n",
       "      <th>MORT_30_PN</th>\n",
       "      <th>MORT_30_STK</th>\n",
       "      <th>PSI_12_POSTOP_PULMEMB_DVT</th>\n",
       "      <th>PSI_14_POSTOP_DEHIS</th>\n",
       "      <th>PSI_15_ACC_LAC</th>\n",
       "      <th>PSI_4_SURG_COMP</th>\n",
       "      <th>PSI_6_IAT_PTX</th>\n",
       "      <th>PSI_90_SAFETY</th>\n",
       "      <th>READM_30_AMI</th>\n",
       "      <th>READM_30_COPD</th>\n",
       "      <th>READM_30_HF</th>\n",
       "      <th>READM_30_HIP_KNEE</th>\n",
       "      <th>READM_30_HOSP_WIDE</th>\n",
       "      <th>READM_30_PN</th>\n",
       "      <th>READM_30_STK</th>\n",
       "      <th>Closure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8233.000000</td>\n",
       "      <td>7282.000000</td>\n",
       "      <td>10900.000000</td>\n",
       "      <td>10995.000000</td>\n",
       "      <td>12275.000000</td>\n",
       "      <td>8284.000000</td>\n",
       "      <td>9036.000000</td>\n",
       "      <td>7751.000000</td>\n",
       "      <td>9631.000000</td>\n",
       "      <td>5502.000000</td>\n",
       "      <td>9650.000000</td>\n",
       "      <td>9706.000000</td>\n",
       "      <td>6632.000000</td>\n",
       "      <td>11103.000000</td>\n",
       "      <td>11212.000000</td>\n",
       "      <td>8266.000000</td>\n",
       "      <td>13305.000000</td>\n",
       "      <td>12309.000000</td>\n",
       "      <td>8109.000000</td>\n",
       "      <td>14102.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.185461</td>\n",
       "      <td>14.363142</td>\n",
       "      <td>7.913459</td>\n",
       "      <td>11.959345</td>\n",
       "      <td>13.345222</td>\n",
       "      <td>15.044532</td>\n",
       "      <td>4.518752</td>\n",
       "      <td>1.978051</td>\n",
       "      <td>1.726129</td>\n",
       "      <td>124.304022</td>\n",
       "      <td>0.400696</td>\n",
       "      <td>0.848702</td>\n",
       "      <td>17.252141</td>\n",
       "      <td>20.345375</td>\n",
       "      <td>22.234267</td>\n",
       "      <td>4.895717</td>\n",
       "      <td>15.470943</td>\n",
       "      <td>17.133959</td>\n",
       "      <td>12.886496</td>\n",
       "      <td>0.003120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.609817</td>\n",
       "      <td>1.343128</td>\n",
       "      <td>1.067743</td>\n",
       "      <td>1.469456</td>\n",
       "      <td>2.866427</td>\n",
       "      <td>1.712835</td>\n",
       "      <td>1.722131</td>\n",
       "      <td>0.435237</td>\n",
       "      <td>0.644749</td>\n",
       "      <td>20.741338</td>\n",
       "      <td>0.072136</td>\n",
       "      <td>0.183101</td>\n",
       "      <td>1.119150</td>\n",
       "      <td>1.313005</td>\n",
       "      <td>1.610627</td>\n",
       "      <td>0.664587</td>\n",
       "      <td>0.889226</td>\n",
       "      <td>1.292103</td>\n",
       "      <td>1.174144</td>\n",
       "      <td>0.055773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.400000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>56.260000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.800000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>109.320000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.100000</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>123.605000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>20.300000</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>2.230000</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>137.985000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.900000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>23.800000</td>\n",
       "      <td>20.880000</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>7.220000</td>\n",
       "      <td>212.160000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>31.700000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 362
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "source": [
    "da_[da_['Closure']==0].describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       COMP_HIP_KNEE  MORT_30_AMI  MORT_30_COPD    MORT_30_HF    MORT_30_PN  \\\n",
       "count    8221.000000  7273.000000  10863.000000  10957.000000  12235.000000   \n",
       "mean        3.185099    14.362711      7.914269     11.959140     13.346596   \n",
       "std         0.609950     1.343669      1.068279      1.469459      2.867720   \n",
       "min         1.400000     9.400000      4.600000      6.000000      6.400000   \n",
       "25%         2.800000    13.500000      7.200000     11.000000     11.100000   \n",
       "50%         3.100000    14.300000      7.800000     11.900000     12.800000   \n",
       "75%         3.500000    15.200000      8.500000     12.900000     15.400000   \n",
       "max         6.900000    20.600000     14.100000     18.500000     26.800000   \n",
       "\n",
       "       MORT_30_STK  PSI_12_POSTOP_PULMEMB_DVT  PSI_14_POSTOP_DEHIS  \\\n",
       "count  8271.000000                9010.000000          7733.000000   \n",
       "mean     15.043659                   4.519696             1.978374   \n",
       "std       1.713782                   1.724203             0.435590   \n",
       "min       8.600000                   0.860000             0.860000   \n",
       "25%      13.900000                   3.430000             1.650000   \n",
       "50%      14.900000                   4.200000             1.880000   \n",
       "75%      16.100000                   5.200000             2.230000   \n",
       "max      23.800000                  20.880000             4.980000   \n",
       "\n",
       "       PSI_15_ACC_LAC  PSI_4_SURG_COMP  PSI_6_IAT_PTX  PSI_90_SAFETY  \\\n",
       "count     9588.000000      5500.000000    9607.000000    9662.000000   \n",
       "mean         1.726448       124.310815       0.400687       0.848923   \n",
       "std          0.645932        20.742026       0.072229       0.183411   \n",
       "min          0.260000        56.260000       0.180000       0.370000   \n",
       "25%          1.300000       109.327500       0.360000       0.730000   \n",
       "50%          1.630000       123.610000       0.390000       0.830000   \n",
       "75%          2.020000       137.990000       0.430000       0.930000   \n",
       "max          7.220000       212.160000       0.880000       2.140000   \n",
       "\n",
       "       READM_30_AMI  READM_30_COPD   READM_30_HF  READM_30_HIP_KNEE  \\\n",
       "count   6625.000000   11063.000000  11174.000000        8254.000000   \n",
       "mean      17.251366      20.345774     22.233775           4.895323   \n",
       "std        1.119373       1.314243      1.611879           0.664577   \n",
       "min       13.100000      15.500000     15.800000           2.400000   \n",
       "25%       16.500000      19.500000     21.200000           4.500000   \n",
       "50%       17.200000      20.300000     22.100000           4.800000   \n",
       "75%       18.000000      21.100000     23.200000           5.300000   \n",
       "max       21.700000      28.000000     31.700000           9.400000   \n",
       "\n",
       "       READM_30_HOSP_WIDE   READM_30_PN  READM_30_STK  Closure  \n",
       "count        13265.000000  12268.000000   8097.000000  14058.0  \n",
       "mean            15.470863     17.133306     12.886069      0.0  \n",
       "std              0.889822      1.292903      1.174580      0.0  \n",
       "min             10.800000     12.900000      8.700000      0.0  \n",
       "25%             14.900000     16.300000     12.100000      0.0  \n",
       "50%             15.400000     17.000000     12.800000      0.0  \n",
       "75%             15.900000     17.900000     13.500000      0.0  \n",
       "max             21.400000     24.700000     18.500000      0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMP_HIP_KNEE</th>\n",
       "      <th>MORT_30_AMI</th>\n",
       "      <th>MORT_30_COPD</th>\n",
       "      <th>MORT_30_HF</th>\n",
       "      <th>MORT_30_PN</th>\n",
       "      <th>MORT_30_STK</th>\n",
       "      <th>PSI_12_POSTOP_PULMEMB_DVT</th>\n",
       "      <th>PSI_14_POSTOP_DEHIS</th>\n",
       "      <th>PSI_15_ACC_LAC</th>\n",
       "      <th>PSI_4_SURG_COMP</th>\n",
       "      <th>PSI_6_IAT_PTX</th>\n",
       "      <th>PSI_90_SAFETY</th>\n",
       "      <th>READM_30_AMI</th>\n",
       "      <th>READM_30_COPD</th>\n",
       "      <th>READM_30_HF</th>\n",
       "      <th>READM_30_HIP_KNEE</th>\n",
       "      <th>READM_30_HOSP_WIDE</th>\n",
       "      <th>READM_30_PN</th>\n",
       "      <th>READM_30_STK</th>\n",
       "      <th>Closure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8221.000000</td>\n",
       "      <td>7273.000000</td>\n",
       "      <td>10863.000000</td>\n",
       "      <td>10957.000000</td>\n",
       "      <td>12235.000000</td>\n",
       "      <td>8271.000000</td>\n",
       "      <td>9010.000000</td>\n",
       "      <td>7733.000000</td>\n",
       "      <td>9588.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>9607.000000</td>\n",
       "      <td>9662.000000</td>\n",
       "      <td>6625.000000</td>\n",
       "      <td>11063.000000</td>\n",
       "      <td>11174.000000</td>\n",
       "      <td>8254.000000</td>\n",
       "      <td>13265.000000</td>\n",
       "      <td>12268.000000</td>\n",
       "      <td>8097.000000</td>\n",
       "      <td>14058.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.185099</td>\n",
       "      <td>14.362711</td>\n",
       "      <td>7.914269</td>\n",
       "      <td>11.959140</td>\n",
       "      <td>13.346596</td>\n",
       "      <td>15.043659</td>\n",
       "      <td>4.519696</td>\n",
       "      <td>1.978374</td>\n",
       "      <td>1.726448</td>\n",
       "      <td>124.310815</td>\n",
       "      <td>0.400687</td>\n",
       "      <td>0.848923</td>\n",
       "      <td>17.251366</td>\n",
       "      <td>20.345774</td>\n",
       "      <td>22.233775</td>\n",
       "      <td>4.895323</td>\n",
       "      <td>15.470863</td>\n",
       "      <td>17.133306</td>\n",
       "      <td>12.886069</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.609950</td>\n",
       "      <td>1.343669</td>\n",
       "      <td>1.068279</td>\n",
       "      <td>1.469459</td>\n",
       "      <td>2.867720</td>\n",
       "      <td>1.713782</td>\n",
       "      <td>1.724203</td>\n",
       "      <td>0.435590</td>\n",
       "      <td>0.645932</td>\n",
       "      <td>20.742026</td>\n",
       "      <td>0.072229</td>\n",
       "      <td>0.183411</td>\n",
       "      <td>1.119373</td>\n",
       "      <td>1.314243</td>\n",
       "      <td>1.611879</td>\n",
       "      <td>0.664577</td>\n",
       "      <td>0.889822</td>\n",
       "      <td>1.292903</td>\n",
       "      <td>1.174580</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.400000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>56.260000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.800000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>109.327500</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.100000</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>123.610000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>20.300000</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>2.230000</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>137.990000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.900000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>23.800000</td>\n",
       "      <td>20.880000</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>7.220000</td>\n",
       "      <td>212.160000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>31.700000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 363
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "source": [
    "da_[da_['Closure']==1].describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       COMP_HIP_KNEE  MORT_30_AMI  MORT_30_COPD  MORT_30_HF  MORT_30_PN  \\\n",
       "count      12.000000     9.000000     37.000000   38.000000   40.000000   \n",
       "mean        3.433333    14.711111      7.675676   12.018421   12.925000   \n",
       "std         0.465800     0.755719      0.876358    1.487217    2.433079   \n",
       "min         2.800000    13.600000      5.800000    9.800000    9.600000   \n",
       "25%         3.125000    14.200000      7.100000   11.000000   11.275000   \n",
       "50%         3.400000    14.900000      7.800000   11.550000   12.250000   \n",
       "75%         3.700000    15.100000      8.200000   12.975000   14.275000   \n",
       "max         4.400000    15.900000      9.800000   15.700000   20.900000   \n",
       "\n",
       "       MORT_30_STK  PSI_12_POSTOP_PULMEMB_DVT  PSI_14_POSTOP_DEHIS  \\\n",
       "count    13.000000                  26.000000            18.000000   \n",
       "mean     15.600000                   4.191538             1.838889   \n",
       "std       0.779957                   0.632757             0.200261   \n",
       "min      14.100000                   2.570000             1.600000   \n",
       "25%      15.100000                   3.805000             1.662500   \n",
       "50%      15.400000                   4.155000             1.835000   \n",
       "75%      16.100000                   4.637500             1.870000   \n",
       "max      16.900000                   5.820000             2.290000   \n",
       "\n",
       "       PSI_15_ACC_LAC  PSI_4_SURG_COMP  PSI_6_IAT_PTX  PSI_90_SAFETY  \\\n",
       "count       43.000000         2.000000      43.000000      44.000000   \n",
       "mean         1.655116       105.625000       0.402791       0.800227   \n",
       "std          0.267887         2.340523       0.047275       0.079606   \n",
       "min          1.060000       103.970000       0.350000       0.620000   \n",
       "25%          1.470000       104.797500       0.380000       0.747500   \n",
       "50%          1.690000       105.625000       0.390000       0.810000   \n",
       "75%          1.820000       106.452500       0.410000       0.860000   \n",
       "max          2.190000       107.280000       0.660000       0.960000   \n",
       "\n",
       "       READM_30_AMI  READM_30_COPD  READM_30_HF  READM_30_HIP_KNEE  \\\n",
       "count      7.000000      40.000000    38.000000          12.000000   \n",
       "mean      17.985714      20.235000    22.378947           5.166667   \n",
       "std        0.530498       0.913025     1.193486           0.641494   \n",
       "min       17.200000      18.400000    20.000000           4.300000   \n",
       "25%       17.650000      19.600000    21.700000           4.700000   \n",
       "50%       18.100000      20.200000    22.250000           5.150000   \n",
       "75%       18.300000      20.850000    23.175000           5.450000   \n",
       "max       18.700000      22.300000    24.400000           6.300000   \n",
       "\n",
       "       READM_30_HOSP_WIDE  READM_30_PN  READM_30_STK  Closure  \n",
       "count           40.000000    41.000000     12.000000     44.0  \n",
       "mean            15.497500    17.329268     13.175000      1.0  \n",
       "std              0.670433     1.018637      0.812544      0.0  \n",
       "min             14.000000    15.100000     11.900000      1.0  \n",
       "25%             15.000000    16.900000     12.525000      1.0  \n",
       "50%             15.600000    17.300000     13.250000      1.0  \n",
       "75%             15.825000    17.900000     13.925000      1.0  \n",
       "max             17.200000    19.700000     14.200000      1.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMP_HIP_KNEE</th>\n",
       "      <th>MORT_30_AMI</th>\n",
       "      <th>MORT_30_COPD</th>\n",
       "      <th>MORT_30_HF</th>\n",
       "      <th>MORT_30_PN</th>\n",
       "      <th>MORT_30_STK</th>\n",
       "      <th>PSI_12_POSTOP_PULMEMB_DVT</th>\n",
       "      <th>PSI_14_POSTOP_DEHIS</th>\n",
       "      <th>PSI_15_ACC_LAC</th>\n",
       "      <th>PSI_4_SURG_COMP</th>\n",
       "      <th>PSI_6_IAT_PTX</th>\n",
       "      <th>PSI_90_SAFETY</th>\n",
       "      <th>READM_30_AMI</th>\n",
       "      <th>READM_30_COPD</th>\n",
       "      <th>READM_30_HF</th>\n",
       "      <th>READM_30_HIP_KNEE</th>\n",
       "      <th>READM_30_HOSP_WIDE</th>\n",
       "      <th>READM_30_PN</th>\n",
       "      <th>READM_30_STK</th>\n",
       "      <th>Closure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.433333</td>\n",
       "      <td>14.711111</td>\n",
       "      <td>7.675676</td>\n",
       "      <td>12.018421</td>\n",
       "      <td>12.925000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>4.191538</td>\n",
       "      <td>1.838889</td>\n",
       "      <td>1.655116</td>\n",
       "      <td>105.625000</td>\n",
       "      <td>0.402791</td>\n",
       "      <td>0.800227</td>\n",
       "      <td>17.985714</td>\n",
       "      <td>20.235000</td>\n",
       "      <td>22.378947</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>15.497500</td>\n",
       "      <td>17.329268</td>\n",
       "      <td>13.175000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.465800</td>\n",
       "      <td>0.755719</td>\n",
       "      <td>0.876358</td>\n",
       "      <td>1.487217</td>\n",
       "      <td>2.433079</td>\n",
       "      <td>0.779957</td>\n",
       "      <td>0.632757</td>\n",
       "      <td>0.200261</td>\n",
       "      <td>0.267887</td>\n",
       "      <td>2.340523</td>\n",
       "      <td>0.047275</td>\n",
       "      <td>0.079606</td>\n",
       "      <td>0.530498</td>\n",
       "      <td>0.913025</td>\n",
       "      <td>1.193486</td>\n",
       "      <td>0.641494</td>\n",
       "      <td>0.670433</td>\n",
       "      <td>1.018637</td>\n",
       "      <td>0.812544</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.800000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.060000</td>\n",
       "      <td>103.970000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.125000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.275000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>3.805000</td>\n",
       "      <td>1.662500</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>104.797500</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.747500</td>\n",
       "      <td>17.650000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>12.525000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.400000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>11.550000</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>4.155000</td>\n",
       "      <td>1.835000</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>105.625000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>22.250000</td>\n",
       "      <td>5.150000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.700000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>12.975000</td>\n",
       "      <td>14.275000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>4.637500</td>\n",
       "      <td>1.870000</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>106.452500</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>18.300000</td>\n",
       "      <td>20.850000</td>\n",
       "      <td>23.175000</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>15.825000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>13.925000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.400000</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>5.820000</td>\n",
       "      <td>2.290000</td>\n",
       "      <td>2.190000</td>\n",
       "      <td>107.280000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>22.300000</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 402
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "source": [
    "da_.drop(columns=['PSI_4_SURG_COMP','READM_30_AMI'],inplace=True)\r\n",
    "#'COMP_HIP_KNEE','MORT_30_AMI','MORT_30_STK''READM_30_HIP_KNEE'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "source": [
    "imputer = KNNImputer()\r\n",
    "dataset_=imputer.fit_transform(da_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "source": [
    "imputer_i=IterativeImputer(max_iter=30)\r\n",
    "imputer_i.fit(da_)\r\n",
    "da_=imputer_i.transform(da_)\r\n",
    "dataset_=da_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "source": [
    "da_.fillna(da_.mean(),inplace=True)\r\n",
    "dataset_=da_.to_numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "source": [
    "train, test = train_test_split(dataset_, test_size=0.3)\r\n",
    "X_train = train[:,:-1]\r\n",
    "Y_train = train[:,-1].astype(int)\r\n",
    "X_test  = test[:,:-1]\r\n",
    "Y_test  = test[:,-1].astype(int)\r\n",
    "X_train.shape, Y_train.shape,X_test.shape, Y_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((9871, 19), (9871,), (4231, 19), (4231,))"
      ]
     },
     "metadata": {},
     "execution_count": 567
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "source": [
    "smote = SMOTE()\r\n",
    "x_smote , y_smote = smote.fit_sample(X_train, Y_train)\r\n",
    "x_train1, y_train1 = x_smote , y_smote\r\n",
    "x_test1 =X_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "source": [
    "m=XGBClassifier()\r\n",
    "m.fit(x_train1, y_train1)\r\n",
    "predict_y = m.predict(x_test1)\r\n",
    "print('ROCAUC score:',roc_auc_score(Y_test, predict_y))\r\n",
    "print('Accuracy score:',accuracy_score(Y_test, predict_y))\r\n",
    "print('F1 score:',f1_score(Y_test, predict_y))\r\n",
    "print(classification_report(Y_test, predict_y))\r\n",
    "confusion_matrix(Y_test, predict_y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\zys\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[06:50:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROCAUC score: 0.8175894011202067\n",
      "Accuracy score: 0.9978728432994564\n",
      "F1 score: 0.6086956521739131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4220\n",
      "           1       0.58      0.64      0.61        11\n",
      "\n",
      "    accuracy                           1.00      4231\n",
      "   macro avg       0.79      0.82      0.80      4231\n",
      "weighted avg       1.00      1.00      1.00      4231\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[4215,    5],\n",
       "       [   4,    7]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 569
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset_[:,:-1],\r\n",
    "                                                    dataset_[:,-1],\r\n",
    "                                                    test_size=0.05,\r\n",
    "                                                    stratify=dataset_[:,-1]\r\n",
    "                                                    )\r\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,\r\n",
    "                                       shuffle=True\r\n",
    "                                       )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "source": [
    "pipeline = imbpipeline(steps = [['smote', SMOTE()],\r\n",
    "                                \r\n",
    "                                ['classifier', RandomForestClassifier()]])\r\n",
    "    \r\n",
    "param_grid = {'classifier__n_estimators':[10,20,30,40,50,60,70,80,90,100,150,200,300,400,500]}\r\n",
    "grid_search = GridSearchCV(estimator=pipeline,\r\n",
    "                           param_grid=param_grid,\r\n",
    "                           scoring='f1',\r\n",
    "                           cv=stratified_kfold,\r\n",
    "                           n_jobs=-1)\r\n",
    "\r\n",
    "grid_search.fit(X_train, y_train)\r\n",
    "cv_score_RF_s = grid_search.best_score_\r\n",
    "test_score_RF_s = grid_search.score(X_test, y_test)\r\n",
    "print(f'Cross-validation score: {cv_score_RF_s}\\nTest score: {test_score_RF_s}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cross-validation score: 0.4413986013986014\n",
      "Test score: 1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "source": [
    "pipeline = imbpipeline(steps = [['ADASYN', ADASYN()],\r\n",
    "                                \r\n",
    "                                ['classifier', RandomForestClassifier()]])\r\n",
    "\r\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,\r\n",
    "                                       shuffle=True\r\n",
    "                                       )\r\n",
    "    \r\n",
    "grid_search = GridSearchCV(estimator=pipeline,\r\n",
    "                           param_grid=param_grid,\r\n",
    "                           scoring='f1',\r\n",
    "                           cv=stratified_kfold,\r\n",
    "                           n_jobs=-1)\r\n",
    "\r\n",
    "grid_search.fit(X_train, y_train)\r\n",
    "cv_score_RF_a = grid_search.best_score_\r\n",
    "test_score_RF_a = grid_search.score(X_test, y_test)\r\n",
    "print(f'Cross-validation score: {cv_score_RF_a}\\nTest score: {test_score_RF_a}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cross-validation score: 0.41216783216783215\n",
      "Test score: 1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "source": [
    "pipeline = imbpipeline(steps = [['SVMSMOTE', SVMSMOTE()],\r\n",
    "                                \r\n",
    "                                ['classifier', RandomForestClassifier()]])\r\n",
    "\r\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,\r\n",
    "                                       shuffle=True\r\n",
    "                                       )\r\n",
    "    \r\n",
    "grid_search = GridSearchCV(estimator=pipeline,\r\n",
    "                           param_grid=param_grid,\r\n",
    "                           \r\n",
    "                           scoring='f1',\r\n",
    "                           cv=stratified_kfold,\r\n",
    "                           n_jobs=-1)\r\n",
    "\r\n",
    "grid_search.fit(X_train, y_train)\r\n",
    "cv_score_RF_svm = grid_search.best_score_\r\n",
    "test_score_RF_svm = grid_search.score(X_test, y_test)\r\n",
    "print(f'Cross-validation score: {cv_score_RF_svm}\\nTest score: {test_score_RF_svm}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cross-validation score: 0.27939393939393936\n",
      "Test score: 0.6666666666666666\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "source": [
    "pipeline = imbpipeline(steps = [['SMOTE', SMOTE()],\r\n",
    "                                \r\n",
    "                                ['classifier', LogisticRegression()]])\r\n",
    "    \r\n",
    "param_grid = {'classifier__C':[0.001, 0.01, 0.1, 1, 10, 100, 1000]}\r\n",
    "grid_search = GridSearchCV(estimator=pipeline,\r\n",
    "                           param_grid=param_grid,\r\n",
    "                           scoring='f1',\r\n",
    "                           cv=stratified_kfold,\r\n",
    "                           n_jobs=-1)\r\n",
    "\r\n",
    "grid_search.fit(X_train, y_train)\r\n",
    "cv_score_LR_s = grid_search.best_score_\r\n",
    "test_score_LR_s= grid_search.score(X_test, y_test)\r\n",
    "print(f'Cross-validation score: {cv_score_LR_s}\\nTest score: {test_score_LR_s}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cross-validation score: 0.030404519651552598\n",
      "Test score: 0.03076923076923077\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\zys\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "source": [
    "pipeline = imbpipeline(steps = [['ADASYN', ADASYN()],\r\n",
    "                                \r\n",
    "                                ['classifier', LogisticRegression()]])\r\n",
    "    \r\n",
    "param_grid = {'classifier__C':[0.001, 0.01, 0.1, 1, 10, 100, 1000]}\r\n",
    "grid_search = GridSearchCV(estimator=pipeline,\r\n",
    "                           param_grid=param_grid,\r\n",
    "                           scoring='f1',\r\n",
    "                           cv=stratified_kfold,\r\n",
    "                           n_jobs=-1)\r\n",
    "\r\n",
    "grid_search.fit(X_train, y_train)\r\n",
    "cv_score_LR_a = grid_search.best_score_\r\n",
    "test_score_LR_a= grid_search.score(X_test, y_test)\r\n",
    "print(f'Cross-validation score: {cv_score_LR_a}\\nTest score: {test_score_LR_a}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cross-validation score: 0.029091498941816618\n",
      "Test score: 0.031007751937984496\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\zys\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "source": [
    "pipeline = imbpipeline(steps = [['SVMSMOTE', SVMSMOTE()],\r\n",
    "                                \r\n",
    "                                ['classifier', LogisticRegression()]])\r\n",
    "    \r\n",
    "param_grid = {'classifier__C':[0.001, 0.01, 0.1, 1, 10, 100, 1000]}\r\n",
    "grid_search = GridSearchCV(estimator=pipeline,\r\n",
    "                           param_grid=param_grid,\r\n",
    "                           scoring='f1',\r\n",
    "                           cv=stratified_kfold,\r\n",
    "                           n_jobs=-1)\r\n",
    "\r\n",
    "grid_search.fit(X_train, y_train)\r\n",
    "cv_score_LR_svm = grid_search.best_score_\r\n",
    "test_score_LR_svm= grid_search.score(X_test, y_test)\r\n",
    "print(f'Cross-validation score: {cv_score_LR_svm}\\nTest score: {test_score_LR_svm}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cross-validation score: 0.018257794855419663\n",
      "Test score: 0.029629629629629624\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\zys\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "source": [
    "pipeline = imbpipeline(steps = [['SMOTE', SMOTE()],\r\n",
    "                                \r\n",
    "                                ['classifier', DecisionTreeClassifier()]])\r\n",
    "    \r\n",
    "param_grid = {'classifier__criterion':['gini','entropy'],'classifier__max_depth':[1,2,3,4,5,10,20,30,50,100,200,500]}\r\n",
    "grid_search = GridSearchCV(estimator=pipeline,\r\n",
    "                           param_grid=param_grid,\r\n",
    "                           scoring='f1',\r\n",
    "                           cv=stratified_kfold,\r\n",
    "                           n_jobs=-1)\r\n",
    "\r\n",
    "grid_search.fit(X_train, y_train)\r\n",
    "cv_score_DT_s = grid_search.best_score_\r\n",
    "test_score_DT_s= grid_search.score(X_test, y_test)\r\n",
    "print(f'Cross-validation score: {cv_score_DT_s}\\nTest score: {test_score_DT_s}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cross-validation score: 0.3005050505050505\n",
      "Test score: 0.3333333333333333\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "source": [
    "pipeline = imbpipeline(steps = [['ADASYN', ADASYN()],\r\n",
    "                                \r\n",
    "                                ['classifier', DecisionTreeClassifier()]])\r\n",
    "    \r\n",
    "param_grid = {'classifier__criterion':['gini','entropy'],'classifier__max_depth':[1,2,3,4,5,10,20,30,50,100,200,500]}\r\n",
    "grid_search = GridSearchCV(estimator=pipeline,\r\n",
    "                           param_grid=param_grid,\r\n",
    "                           scoring='f1',\r\n",
    "                           cv=stratified_kfold,\r\n",
    "                           n_jobs=-1)\r\n",
    "\r\n",
    "grid_search.fit(X_train, y_train)\r\n",
    "cv_score_DT_a = grid_search.best_score_\r\n",
    "test_score_DT_a= grid_search.score(X_test, y_test)\r\n",
    "print(f'Cross-validation score: {cv_score_DT_a}\\nTest score: {test_score_DT_a}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cross-validation score: 0.331133382746286\n",
      "Test score: 0.5714285714285715\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "source": [
    "pipeline = imbpipeline(steps = [['SVMSMOTE',SVMSMOTE()],\r\n",
    "                                \r\n",
    "                                ['classifier', DecisionTreeClassifier()]])\r\n",
    "    \r\n",
    "param_grid = {'classifier__criterion':['gini','entropy'],'classifier__max_depth':[1,2,3,4,5,10,20,30,50,100,200,500]}\r\n",
    "grid_search = GridSearchCV(estimator=pipeline,\r\n",
    "                           param_grid=param_grid,\r\n",
    "                           scoring='f1',\r\n",
    "                           cv=stratified_kfold,\r\n",
    "                           n_jobs=-1)\r\n",
    "\r\n",
    "grid_search.fit(X_train, y_train)\r\n",
    "cv_score_DT_svm = grid_search.best_score_\r\n",
    "test_score_DT_svm= grid_search.score(X_test, y_test)\r\n",
    "print(f'Cross-validation score: {cv_score_DT_svm}\\nTest score: {test_score_DT_svm}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cross-validation score: 0.2715294117647059\n",
      "Test score: 0.28571428571428575\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "source": [
    "pipeline = imbpipeline(steps = [['SMOTE',SMOTE()],\r\n",
    "                                \r\n",
    "                                ['classifier', XGBClassifier()]])\r\n",
    "    \r\n",
    "param_grid = {'classifier__min_child_weight': [1, 5, 10]\r\n",
    "        }\r\n",
    "grid_search = GridSearchCV(estimator=pipeline,\r\n",
    "                           param_grid=param_grid,\r\n",
    "                           scoring='f1',\r\n",
    "                           cv=stratified_kfold,\r\n",
    "                           n_jobs=-1)\r\n",
    "\r\n",
    "grid_search.fit(X_train, y_train)\r\n",
    "cv_score_xgb_s = grid_search.best_score_\r\n",
    "test_score_xgb_s= grid_search.score(X_test, y_test)\r\n",
    "print(f'Cross-validation score: {cv_score_xgb_s}\\nTest score: {test_score_xgb_s}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\zys\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[06:51:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Cross-validation score: 0.6029284441049148\n",
      "Test score: 0.8\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "source": [
    "pipeline = imbpipeline(steps = [['ADASYN', ADASYN()],\r\n",
    "                                \r\n",
    "                                ['classifier', XGBClassifier()]])\r\n",
    "\r\n",
    "grid_search = GridSearchCV(estimator=pipeline,\r\n",
    "                           param_grid=param_grid,\r\n",
    "                           scoring='f1',\r\n",
    "                           cv=stratified_kfold,\r\n",
    "                           n_jobs=-1)\r\n",
    "\r\n",
    "grid_search.fit(X_train, y_train)\r\n",
    "cv_score_xgb_a = grid_search.best_score_\r\n",
    "test_score_xgb_a= grid_search.score(X_test, y_test)\r\n",
    "print(f'Cross-validation score: {cv_score_xgb_a}\\nTest score: {test_score_xgb_a}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\zys\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[06:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Cross-validation score: 0.5963725490196079\n",
      "Test score: 0.5714285714285715\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "source": [
    "pipeline = imbpipeline(steps = [['SVMSMOTE', SVMSMOTE()],\r\n",
    "                                \r\n",
    "                                ['classifier', XGBClassifier()]])\r\n",
    "param_grid = {'classifier__min_child_weight': [1, 5, 10]\r\n",
    "        }    \r\n",
    "grid_search = GridSearchCV(estimator=pipeline,\r\n",
    "                           param_grid=param_grid,\r\n",
    "                           scoring='f1',\r\n",
    "                           cv=stratified_kfold,\r\n",
    "                           n_jobs=-1)\r\n",
    "\r\n",
    "grid_search.fit(X_train, y_train)\r\n",
    "cv_score_xgb_svm = grid_search.best_score_\r\n",
    "test_score_xgb_svm= grid_search.score(X_test, y_test)\r\n",
    "print(f'Cross-validation score: {cv_score_xgb_svm}\\nTest score: {test_score_xgb_svm}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\zys\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[06:53:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Cross-validation score: 0.5013986013986014\n",
      "Test score: 0.4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "source": [
    "pipeline = imbpipeline(steps = [['SMOTE', SMOTE()],\r\n",
    "                                \r\n",
    "                                ['classifier', HistGradientBoostingClassifier()]])\r\n",
    "    \r\n",
    "param_grid = {'classifier__min_samples_leaf': [1,2,3,4, 5, 10]\r\n",
    "        }\r\n",
    "grid_search = GridSearchCV(estimator=pipeline,\r\n",
    "                           param_grid=param_grid,\r\n",
    "                           scoring='f1',\r\n",
    "                           cv=stratified_kfold,\r\n",
    "                           n_jobs=-1)\r\n",
    "\r\n",
    "grid_search.fit(X_train, y_train)\r\n",
    "cv_score_xgb_s = grid_search.best_score_\r\n",
    "test_score_xgb_s= grid_search.score(X_test, y_test)\r\n",
    "print(f'Cross-validation score: {cv_score_xgb_s}\\nTest score: {test_score_xgb_s}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cross-validation score: 0.5049127343244991\n",
      "Test score: 0.8\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "source": [
    "stacking_clf=StackingClassifier(estimators=[('rf',RandomForestClassifier()),('xg',XGBClassifier()),('dt',DecisionTreeClassifier()),('hg',HistGradientBoostingClassifier())])\r\n",
    "pipeline = imbpipeline(steps = [['SMOTE', ADASYN()],\r\n",
    "                                \r\n",
    "                                ['classifier', stacking_clf]])\r\n",
    "    \r\n",
    "param_grid = {'classifier__rf__n_estimators':[10,20,30,40,50,60,70,80,90,100,150,200,300,400,500],'classifier__xg__min_child_weight': [1, 5, 10],'classifier__hg__min_samples_leaf': [1, 5, 10]\r\n",
    "        }\r\n",
    "grid_search = GridSearchCV(estimator=pipeline,\r\n",
    "                           param_grid=param_grid,\r\n",
    "                           scoring='f1',\r\n",
    "                           cv=stratified_kfold,\r\n",
    "                           n_jobs=-1)\r\n",
    "\r\n",
    "grid_search.fit(X_train, y_train)\r\n",
    "cv_score_xgb_s = grid_search.best_score_\r\n",
    "test_score_xgb_s= grid_search.score(X_test, y_test)\r\n",
    "print(f'Cross-validation score: {cv_score_xgb_s}\\nTest score: {test_score_xgb_s}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\zys\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[01:34:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\zys\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[01:35:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\zys\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[01:35:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\zys\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[01:35:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\zys\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[01:35:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\zys\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[01:35:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Cross-validation score: 0.5655011655011655\n",
      "Test score: 0.5384615384615384\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "\r\n",
    "#voting.get_params().keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['estimators', 'flatten_transform', 'n_jobs', 'verbose', 'voting', 'weights', 'rf', 'xg', 'dt', 'hg', 'rf__bootstrap', 'rf__ccp_alpha', 'rf__class_weight', 'rf__criterion', 'rf__max_depth', 'rf__max_features', 'rf__max_leaf_nodes', 'rf__max_samples', 'rf__min_impurity_decrease', 'rf__min_impurity_split', 'rf__min_samples_leaf', 'rf__min_samples_split', 'rf__min_weight_fraction_leaf', 'rf__n_estimators', 'rf__n_jobs', 'rf__oob_score', 'rf__random_state', 'rf__verbose', 'rf__warm_start', 'xg__objective', 'xg__use_label_encoder', 'xg__base_score', 'xg__booster', 'xg__colsample_bylevel', 'xg__colsample_bynode', 'xg__colsample_bytree', 'xg__gamma', 'xg__gpu_id', 'xg__importance_type', 'xg__interaction_constraints', 'xg__learning_rate', 'xg__max_delta_step', 'xg__max_depth', 'xg__min_child_weight', 'xg__missing', 'xg__monotone_constraints', 'xg__n_estimators', 'xg__n_jobs', 'xg__num_parallel_tree', 'xg__random_state', 'xg__reg_alpha', 'xg__reg_lambda', 'xg__scale_pos_weight', 'xg__subsample', 'xg__tree_method', 'xg__validate_parameters', 'xg__verbosity', 'dt__ccp_alpha', 'dt__class_weight', 'dt__criterion', 'dt__max_depth', 'dt__max_features', 'dt__max_leaf_nodes', 'dt__min_impurity_decrease', 'dt__min_impurity_split', 'dt__min_samples_leaf', 'dt__min_samples_split', 'dt__min_weight_fraction_leaf', 'dt__random_state', 'dt__splitter', 'hg__categorical_features', 'hg__early_stopping', 'hg__l2_regularization', 'hg__learning_rate', 'hg__loss', 'hg__max_bins', 'hg__max_depth', 'hg__max_iter', 'hg__max_leaf_nodes', 'hg__min_samples_leaf', 'hg__monotonic_cst', 'hg__n_iter_no_change', 'hg__random_state', 'hg__scoring', 'hg__tol', 'hg__validation_fraction', 'hg__verbose', 'hg__warm_start'])"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "source": [
    "models = pd.DataFrame({\r\n",
    "    'Model': ['Random Forest', 'Logistic Regression', \r\n",
    "              'Decision Tree',  \r\n",
    "              'Gradient Boosting','Stacking'],\r\n",
    "    'SMOTE': [cv_score_RF_s,cv_score_LR_s,cv_score_DT_s,cv_score_xgb_s,np.NaN],\r\n",
    "    'ADASYN': [cv_score_RF_a,cv_score_LR_a,cv_score_DT_a,cv_score_xgb_a,0.56550116],\r\n",
    "    'SVMSMOTE':[cv_score_RF_svm,cv_score_LR_svm,cv_score_DT_svm,cv_score_xgb_svm,np.nan]\r\n",
    "    })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "source": [
    "models"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 Model     SMOTE    ADASYN  SVMSMOTE\n",
       "0        Random Forest  0.441399  0.412168  0.279394\n",
       "1  Logistic Regression  0.030405  0.029091  0.018258\n",
       "2        Decision Tree  0.300505  0.331133  0.271529\n",
       "3    Gradient Boosting  0.602928  0.596373  0.501399\n",
       "4             Stacking       NaN  0.565501       NaN"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>SMOTE</th>\n",
       "      <th>ADASYN</th>\n",
       "      <th>SVMSMOTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.412168</td>\n",
       "      <td>0.279394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.030405</td>\n",
       "      <td>0.029091</td>\n",
       "      <td>0.018258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.300505</td>\n",
       "      <td>0.331133</td>\n",
       "      <td>0.271529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.602928</td>\n",
       "      <td>0.596373</td>\n",
       "      <td>0.501399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.565501</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 581
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "e46a312f18d66f7c51dddd93e62c13ef1a00dedabbfab58bbf9c547c81fcfc71"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}